{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_SA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN6LAoMbteqTWPBheqUEEMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katinder/Deep-Learning-Mini-Projects/blob/main/LSTM_SA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentiment analysis using Keras imdb dataset"
      ],
      "metadata": {
        "id": "YOin5dS6hO-7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PRLIrs-6hCVo"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=imdb.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Syq0RLyHhNfm",
        "outputId": "4453d9db-2fbb-4faf-e09f-e3f1a54ed296"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reviews in this dataset are already pre-processed and encoded into work indexes (default indexing is done on the basis of word-frequency, more the frequency smaller the index)"
      ],
      "metadata": {
        "id": "2-HinW4GhhU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### preprocess"
      ],
      "metadata": {
        "id": "MG_HXqCvh6X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import backend as k\n",
        "from keras.layers import LSTM, Embedding, Activation, Dense\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "aG7ZQm3shcLM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_words=500\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=top_words)"
      ],
      "metadata": {
        "id": "DNQ6kH3hiMM7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RP0uVqkjqjl",
        "outputId": "fca60462-8e18-423d-8722-15df9219e78e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y6QNGYEjiTo",
        "outputId": "0f1a071f-c4f7-49c2-934a-11a5e91b2129"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train[1]))\n",
        "print(len(x_train[20]))\n",
        "print(len(set(y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoL_l2DRjmUR",
        "outputId": "f651cb8c-c660-44ac-f9ee-3a2123969e0f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189\n",
            "129\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pad to make every review the same lenght\n",
        "from keras.preprocessing import sequence\n",
        "max_len=500\n",
        "x_train=sequence.pad_sequences(x_train,maxlen=max_len)\n",
        "x_test=sequence.pad_sequences(x_test,maxlen=max_len)"
      ],
      "metadata": {
        "id": "r--4m_hoiZN6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train[1]),len(x_train[20]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iwV-duujZQM",
        "outputId": "301a18ea-c38f-46bb-e6a0-9cfbb0f9878d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dictionary to convert back\n",
        "word_to_id=keras.datasets.imdb.get_word_index()\n",
        "for x in list(word_to_id)[0:5]:\n",
        "  print(x, word_to_id[x])\n",
        "\n",
        "#shift by one\n",
        "word_to_id={k:(v+1) for k,v in word_to_id.items()}\n",
        "for x in list(word_to_id)[0:5]:\n",
        "  print(x, word_to_id[x])\n",
        "\n",
        "# add 0,1,2\n",
        "word_to_id[\"<PAD>\"]=0\n",
        "word_to_id[\"<START>\"]=1\n",
        "\n",
        "#reverse dictionary\n",
        "id_to_word={val:key for key,val in word_to_id.items()}\n",
        "for x in list(id_to_word)[0:5]:\n",
        "  print(x, id_to_word[x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VITv34MQkS7W",
        "outputId": "dbfad603-e390-46b5-b6ba-e25987327ecf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fawn 34701\n",
            "tsukino 52006\n",
            "nunnery 52007\n",
            "sonja 16816\n",
            "vani 63951\n",
            "fawn 34702\n",
            "tsukino 52007\n",
            "nunnery 52008\n",
            "sonja 16817\n",
            "vani 63952\n",
            "34702 fawn\n",
            "52007 tsukino\n",
            "52008 nunnery\n",
            "16817 sonja\n",
            "63952 vani\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNAdIaaOm_MD",
        "outputId": "f320274a-d85b-4741-f520-bb510de9eb99"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   1  14  22  16  43   2\n",
            "   2   2   2  65 458   2  66   2   4 173  36 256   5  25 100  43   2 112\n",
            "  50   2   2   9  35 480 284   5 150   4 172 112 167   2 336 385  39   4\n",
            " 172   2   2  17   2  38  13 447   4 192  50  16   6 147   2  19  14  22\n",
            "   4   2   2 469   4  22  71  87  12  16  43   2  38  76  15  13   2   4\n",
            "  22  17   2  17  12  16   2  18   2   5  62 386  12   8 316   8 106   5\n",
            "   4   2   2  16 480  66   2  33   4 130  12  16  38   2   5  25 124  51\n",
            "  36 135  48  25   2  33   6  22  12 215  28  77  52   5  14 407  16  82\n",
            "   2   8   4 107 117   2  15 256   4   2   7   2   5   2  36  71  43   2\n",
            " 476  26 400 317  46   7   4   2   2  13 104  88   4 381  15 297  98  32\n",
            "   2  56  26 141   6 194   2  18   4 226  22  21 134 476  26 480   5 144\n",
            "  30   2  18  51  36  28 224  92  25 104   4 226  65  16  38   2  88  12\n",
            "  16 283   5  16   2 113 103  32  15  16   2  19 178  32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_word[14]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zRZjHGaXnO0j",
        "outputId": "cad73424-d6c9-476a-8747-edcb8112d3e4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'was'"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join(id_to_word[id] for id in x_train[0] ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONlUMTSgkwTC",
        "outputId": "f61ae640-f064-49e6-deff-e6384dc59481"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> was not for it's the the the the see already the their the a every so found of his movies it's the plot good the the in who guess wasn't of doesn't a again plot find the poor let her a again the the with the like that oh a big good for to watching the but was not a the the turn a not well how this for it's the like bad as that the a not with the with this for the movie the of only moments this br special br films of a the the for guess their the an a man this for like the of his ever more so while there his the an to not this role be get when of was others for people the br a character love the as found a the is the of the so well it's the fine have early seeing if is a the the that watch him a sex as plays could by the time have through to long the movie a music not on scene fine have guess of i'm all the movie more so be whole its his watch a music see for like the him this for everything of for the never characters by as for the but down by\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "fAFgeTH-pG4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector_length=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(top_words,embedding_vector_length, input_length=max_len))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid')) #binary classification\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX-v-Hm3mI-K",
        "outputId": "3ea026d2-4987-45a1-9f68-3a2078efbc64"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 32)           16000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               53200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,301\n",
            "Trainable params: 69,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### training"
      ],
      "metadata": {
        "id": "DLbeJreep1Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=2,batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm4hDVCEpt1t",
        "outputId": "1260b5a2-15e5-4bb5-c6fd-334733da2a32"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "196/196 [==============================] - 301s 2s/step - loss: 0.5832 - accuracy: 0.6830 - val_loss: 0.4794 - val_accuracy: 0.7743\n",
            "Epoch 2/2\n",
            "196/196 [==============================] - 260s 1s/step - loss: 0.5050 - accuracy: 0.7664 - val_loss: 0.5451 - val_accuracy: 0.7297\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f69ed5d0910>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('imdb.h5')"
      ],
      "metadata": {
        "id": "M6ljPF7ArYPf"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### evaluate"
      ],
      "metadata": {
        "id": "QZz9_2tVrKan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores=model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Accuracy: \",scores[1]*100)\n",
        "print(\"Loss: \",scores[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br6tsB92qJHB",
        "outputId": "86662514-deba-452a-e5a8-ba2a47c045a4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  72.97199964523315\n",
            "Loss:  0.5451398491859436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check for input"
      ],
      "metadata": {
        "id": "qtdvvGk3qea2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "r1=\"it was really fun\"\n",
        "r2=\"not fun\"\n",
        "\n",
        "for review in [r1,r2]:\n",
        "  tmp=[]\n",
        "  for w in review.split(\" \"):\n",
        "    tmp.append(word_to_id[w])\n",
        "  tmp_padded=sequence.pad_sequences([tmp],maxlen=max_len)\n",
        "  print(f\"{review}: {model.predict(np.array([tmp_padded][0]))}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdvJliMGqgYO",
        "outputId": "bd6724c8-edf0-467a-a965-a1ffb54c3d04"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it was really fun: [[0.19110912]]\n",
            "not fun: [[0.39025202]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kwsYelEhs1aC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}